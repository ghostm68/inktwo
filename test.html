<html lang="en">
	<head>
		<title>three.js webgpu - audio processing</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<link type="text/css" rel="stylesheet" href="example.css">
		<style>
body {
	margin: 0;
	background-color: #000;
	overscroll-behavior: none;
	overflow: hidden;
	height: 100%;
}

a {
	text-decoration: none;
	color: inherit;
}

#info {
	position: fixed;
	top: 15px;
	left: 15px;
	z-index: 1001;

	display: grid;
	grid-template-columns: 50px auto;
	grid-template-rows: auto auto;
	column-gap: 10px;
	align-items: start;
	color: #e0e0e0;
	text-shadow: 1px 1px 5px rgba(0, 0, 0, .7);
	font: 400 14px 'Inter', 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
}

#info > a.logo-link {
	grid-column: 1;
	grid-row: 1 / span 2;
	display: block;
	width: 50px;
	height: 50px;
	background: no-repeat center / contain;
	background-image: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 226.77 226.77"><g transform="translate(8.964 4.2527)" stroke="%23ffffff" stroke-linecap="butt" stroke-linejoin="round" stroke-width="4" fill="none"><path d="m63.02 200.61-43.213-174.94 173.23 49.874z"/><path d="m106.39 50.612 21.591 87.496-86.567-24.945z"/><path d="m84.91 125.03-10.724-43.465 43.008 12.346z"/><path d="m63.458 38.153 10.724 43.465-43.008-12.346z"/><path d="m149.47 62.93 10.724 43.465-43.008-12.346z"/><path d="m84.915 125.06 10.724 43.465-43.008-12.346z"/></g></svg>');
}

.title-wrapper {
	position: absolute;
    left: 60px;
    top: 2px;
    display: flex;
    width: 300px;
}

#info > small {
	font-size: 12px;
	color: #e0e0e0;
	position: absolute;
	left: 60px;
	top: 25px;
	width: calc( 100vw - 250px );
	line-height: 20px;
}

.title-wrapper > a {
	font-weight: 600;
}

.title-wrapper > span {
	opacity: .7;
	position: relative;
	padding-left: 12px;
	margin-left: 10px;
}

#info > small a {
	color: #ff0;
	text-decoration: none;
}

#info > small a:hover {
	text-decoration: underline;
}

.title-wrapper > span::before {
	content: "";
	position: absolute;
	left: 1px;
	top: calc(50% + 1px);
	transform: translateY(-50%);
	width: 1px;
	height: 12px;
	background: #c3c3c3;
	opacity: .5;
}

#info.invert {
	filter: invert(1);
}

#overlay {
	position: absolute;
	font-size: 16px;
	z-index: 2;
	top: 0;
	left: 0;
	width: 100%;
	height: 100%;
	display: flex;
	align-items: center;
	justify-content: center;
	flex-direction: column;
	background: rgba(0,0,0,0.7);
}

#overlay button {
	background: transparent;
	border: 0;
	border: 1px solid rgb(255, 255, 255);
	border-radius: 4px;
	color: #ffffff;
	padding: 12px 18px;
	text-transform: uppercase;
	cursor: pointer;
}			
/* canvas container becomes the positioning root */
#renderContainer {
    position: relative;
    width: 100vw;
    height: 100vh;
}

/* example overlays */
.topLeftHUD {
    position: absolute;
    top: 1rem;
    left: 1rem;
    color: #00ffcc;
    font-family: monospace;
    font-size: 0.9rem;
    background: rgba(0,0,0,.35);
    padding: .4rem .6rem;
    border-radius: 4px;
    pointer-events: none;   /* lets clicks fall through to the canvas */
    z-index: 10;
}

.bottomBar {
    position: absolute;
    bottom: 0;
    left: 0;
    right: 0;
    height: 48px;
    background: rgba(0,0,0,.5);
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 1rem;
    z-index: 10;
}

.bottomBar button {
    pointer-events: auto;   /* keep buttons clickable */
}
</style>

<!-- rename the container so we can style it -->
<script>
// change
container.id = 'renderContainer';
document.body.appendChild(container);
</script>

<!-- overlay elements -->
<div class="topLeftHUD">pitch: <span id="pitchDisplay">1.5</span></div>

<div class="bottomBar">
    <button id="btnPlay">Play</button>
    <button id="btnStop">Stop</button>
</div>

<!-- wire the new buttons (optional) -->
<script>
document.getElementById('btnPlay').addEventListener('click', playAudioBuffer);
document.getElementById('btnStop').addEventListener('click', () => {
    if (currentAudio) currentAudio.stop();
});
// keep the HUD label in sync
gui.controllers[0].onChange(v => document.getElementById('pitchDisplay').textContent = v.toFixed(2));
</script>
	</head>
	<body>

		<div id="overlay">
			<button id="startButton">Play</button>
		</div>

		<div id="info">
			<a href="https://threejs.org/" target="_blank" rel="noopener" class="logo-link"></a>

			<div class="title-wrapper">
				<a href="https://threejs.org/" target="_blank" rel="noopener">three.js</a><span>Audio Processing</span>
			</div>

			<small>Click on screen to process the audio using WebGPU.</small>
		</div>

		<script type="importmap">
			{
				"imports": {
					"three": "../build/three.webgpu.js",
					"three/webgpu": "../build/three.webgpu.js",
					"three/tsl": "../build/three.tsl.js",
					"three/addons/": "./jsm/"
				}
			}
		</script>

		<script type="module">

			import * as THREE from 'three/webgpu';
			import { Fn, uniform, instanceIndex, instancedArray, float, texture, screenUV, color } from 'three/tsl';

			import { Inspector } from 'three/addons/inspector/Inspector.js';

			let camera, scene, renderer;
			let computeNode;
			let waveBuffer, sampleRate;
			let waveArray;
			let currentAudio, currentAnalyser;
			const analyserBuffer = new Uint8Array( 1024 );
			let analyserTexture;

			const startButton = document.getElementById( 'startButton' );
			startButton.addEventListener( 'click', init );

			async function playAudioBuffer() {

				if ( currentAudio ) currentAudio.stop();

				// compute audio

				renderer.compute( computeNode );

				const wave = new Float32Array( await renderer.getArrayBufferAsync( waveArray.value ) );

				// play result

				const audioOutputContext = new AudioContext( { sampleRate } );
				const audioOutputBuffer = audioOutputContext.createBuffer( 1, wave.length, sampleRate );

				audioOutputBuffer.copyToChannel( wave, 0 );

				const source = audioOutputContext.createBufferSource();
				source.connect( audioOutputContext.destination );
				source.buffer = audioOutputBuffer;
				source.start();

				currentAudio = source;

				// visual feedback

				currentAnalyser = audioOutputContext.createAnalyser();
				currentAnalyser.fftSize = 2048;

				source.connect( currentAnalyser );

			}

			async function init() {

				const overlay = document.getElementById( 'overlay' );
				overlay.remove();

				// audio buffer

				const soundBuffer = await fetch( 'sounds/webgpu-audio-processing.mp3' ).then( res => res.arrayBuffer() );
				const audioContext = new AudioContext();

				const audioBuffer = await audioContext.decodeAudioData( soundBuffer );

				waveBuffer = audioBuffer.getChannelData( 0 );

				// adding extra silence to delay and pitch
				waveBuffer = new Float32Array( [ ...waveBuffer, ...new Float32Array( 200000 ) ] );

				sampleRate = audioBuffer.sampleRate / audioBuffer.numberOfChannels;

				// create webgpu buffers

				waveArray = instancedArray( waveBuffer );

				// read-only buffer

				const originalWave = instancedArray( waveBuffer ).toReadOnly();

				// The Pixel Buffer Object (PBO) is required to get the GPU computed data to the CPU in the WebGL2 fallback.
				// As used in `renderer.getArrayBufferAsync( waveArray.value )`.

				originalWave.setPBO( true );
				waveArray.setPBO( true );

				// params

				const pitch = uniform( 1.5 );
				const delayVolume = uniform( .2 );
				const delayOffset = uniform( .55 );


				// compute (shader-node)

				const computeShaderFn = Fn( () => {

					const index = float( instanceIndex );

					// pitch

					const time = index.mul( pitch );

					let wave = originalWave.element( time );


					// delay

					for ( let i = 1; i < 7; i ++ ) {

						const waveOffset = originalWave.element( index.sub( delayOffset.mul( sampleRate ).mul( i ) ).mul( pitch ) );
						const waveOffsetVolume = waveOffset.mul( delayVolume.div( i * i ) );

						wave = wave.add( waveOffsetVolume );

					}


					// store

					const waveStorageElementNode = waveArray.element( instanceIndex );

					waveStorageElementNode.assign( wave );

				} );


				// compute

				computeNode = computeShaderFn().compute( waveBuffer.length );

				// renderer

				const container = document.createElement( 'div' );
				document.body.appendChild( container );

				camera = new THREE.PerspectiveCamera( 45, window.innerWidth / window.innerHeight, 0.01, 30 );


				// nodes

				analyserTexture = new THREE.DataTexture( analyserBuffer, analyserBuffer.length, 1, THREE.RedFormat );

				const spectrum = texture( analyserTexture, screenUV.x ).x.mul( screenUV.y );
				const backgroundNode = color( 0x0000FF ).mul( spectrum );


				// scene

				scene = new THREE.Scene();
				scene.backgroundNode = backgroundNode;

				// renderer

				renderer = new THREE.WebGPURenderer( { antialias: true } );
				renderer.setPixelRatio( window.devicePixelRatio );
				renderer.setSize( window.innerWidth, window.innerHeight );
				renderer.setAnimationLoop( render );
				renderer.inspector = new Inspector();
				container.appendChild( renderer.domElement );

				await renderer.init();

				window.addEventListener( 'resize', onWindowResize );
				document.addEventListener( 'click', playAudioBuffer );

				// gui

				const gui = renderer.inspector.createParameters( 'Audio' );

				gui.add( pitch, 'value', .5, 2, 0.01 ).name( 'pitch' );
				gui.add( delayVolume, 'value', 0, 1, .01 ).name( 'delayVolume' );
				gui.add( delayOffset, 'value', .1, 1, .01 ).name( 'delayOffset' );

				//

				playAudioBuffer();

			}

			function onWindowResize() {

				camera.aspect = window.innerWidth / window.innerHeight;
				camera.updateProjectionMatrix();

				renderer.setSize( window.innerWidth, window.innerHeight );

			}

			function render() {

				if ( currentAnalyser ) {

					currentAnalyser.getByteFrequencyData( analyserBuffer );

					analyserTexture.needsUpdate = true;

				}

				renderer.render( scene, camera );

			}

		</script>
	</body>
</html>
